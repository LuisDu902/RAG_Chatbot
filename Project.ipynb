{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG Chatbots for Technical Documentation\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Load and split the document](#load-and-split-the-document)\n",
    "- [Generate and store the embeddings](#generate-and-store-the-embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "This project involves implementing a retrieval augmented generation (RAG) with `LangChain` to create a chatbot for\n",
    "answering questions about technical documentation. The document chosen for this assignment was the following: The European Union Medical Device Regulation - Regulation (EU) 2017/745 (EU MDR). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Install the packages and dependencies to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install langchain\n",
    "%pip install -qU langchain langchain-community langchain-chroma langchain-text-splitters unstructured sentence_transformers langchain-huggingface huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'document.html', 'start_index': 763}\n",
      "\n",
      "After consulting the Committee of the Regions,\n",
      "\n",
      "Acting in accordance with the ordinary legislative procedure (2),\n",
      "\n",
      "Whereas:\n",
      "\n",
      "(1) Council Directive 90/385/EEC ( 3 ) and Council Directive 93/42/EEC ( 4 ) constitute the Union regulatory framework for medical devices, other than in vitro diagnostic medical devices. However, a fundamental revision of those Directives is needed to establish a robust, transparent, predictable and sustainable regulatory framework for medical devices which ensures a high level of safety and health whilst supporting innovation.\n",
      "853\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "file_path = \"document.html\"\n",
    "\n",
    "loader = UnstructuredHTMLLoader(file_path)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "print(f\"{docs[1].metadata}\\n\")\n",
    "print(docs[1].page_content)\n",
    "print(len(docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and store the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store the embeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Retrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first subparagraph shall also apply to system or process requirements to be fulfilled in accordance with this Regulation by economic operators or sponsors, including those relating to quality management systems, risk management, post-market surveillance systems, clinical investigations, clinical evaluation or post-market clinical follow-up (‘PMCF’).\n",
      "\n",
      "References in this Regulation to harmonised standards shall be understood as meaning harmonised standards the references of which have been published in the Official Journal of the European Union.\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"Describe the use harmonized standards\")\n",
    "\n",
    "len(retrieved_docs)\n",
    "\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, but what I'm really doing is making a human-readable document. There are other languages, but those are\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a syntax model. That's why I like it. I've done a lot of programming projects.\\n\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'll do it in no time!\\n\\nOne of the things we learned from talking to my friend\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a command line tool.\\n\\nIf my code is simple enough:\\n\\nif (use (string\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I've been using Language in all my work. Just a small example, let's see a simplified example.\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2', max_length=500, pad_token_id=50256)\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a token: https://huggingface.co/docs/api-inference/quicktour#get-your-api-token\n",
    "# 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\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis.du\\AppData\\Local\\Temp\\ipykernel_20280\\129414242.py:16: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceEndpoint(\n",
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\luis.du\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "repo_id = \"openai-community/gpt2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: filler question\n",
      "\n",
      "Answer: Let's think step by step.\n"
     ]
    }
   ],
   "source": [
    "#from langchain import hub\n",
    "\n",
    "#prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages\n",
    "\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Use three sentences maximum and keep the answer as concise as possible.\n",
      "\n",
      "(99) The requirements of this Regulation should be applicable to all devices placed on the market or put into service from the date of application of this Regulation. However, in order to provide for a smooth transition it should be possible, for a limited period of time from that date, for devices to be placed on the market or put into service by virtue of a valid certificate issued pursuant to Directive 90/385/EEC or pursuant to Directive 93/42/EEC.\n",
      "\n",
      "(100) The European Data Protection Supervisor has given an opinion ( 33 ) pursuant to Article 28(2) of Regulation (EC) No 45/2001.\n",
      "\n",
      "(99) The requirements of this Regulation should be applicable to all devices placed on the market or put into service from the date of application of this Regulation. However, in order to provide for a smooth transition it should be possible, for a limited period of time from that date, for devices to be placed on the market or put into service by virtue of a valid certificate issued pursuant to Directive 90/385/EEC or pursuant to Directive 93/42/EEC.\n",
      "\n",
      "(100) The European Data Protection Supervisor has given an opinion ( 33 ) pursuant to Article 28(2) of Regulation (EC) No 45/2001.\n",
      "\n",
      "(99) The requirements of this Regulation should be applicable to all devices placed on the market or put into service from the date of application of this Regulation. However, in order to provide for a smooth transition it should be possible, for a limited period of time from that date, for devices to be placed on the market or put into service by virtue of a valid certificate issued pursuant to Directive 90/385/EEC or pursuant to Directive 93/42/EEC.\n",
      "\n",
      "(100) The European Data Protection Supervisor has given an opinion ( 33 ) pursuant to Article 28(2) of Regulation (EC) No 45/2001.\n",
      "\n",
      "Question: What does the EU consider a HTC\n",
      "\n",
      "Helpful Answer: If the European Commission decides to require that a particular device be\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "new_llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | new_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(rag_chain.invoke(\"What does the EU consider a HTC\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
