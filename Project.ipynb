{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG Chatbots for Technical Documentation\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Load and split the document](#load-and-split-the-document)\n",
    "- [Generate and store the embeddings](#generate-and-store-the-embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "This project involves implementing a retrieval augmented generation (RAG) with `LangChain` to create a chatbot for\n",
    "answering questions about technical documentation. The document chosen for this assignment was the following: The European Union Medical Device Regulation - Regulation (EU) 2017/745 (EU MDR). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Install the packages and dependencies to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install -qU langchain langchain-community langchain-chroma langchain-text-splitters unstructured sentence_transformers langchain-huggingface huggingface_hub pdfplumber langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='02017R0745 — EN — 09.07.2024 — 004.001 — 1\n",
      "This text is meant purely as a documentation tool and has no legal effect. The Union's institutions do not assume any liability\n",
      "for its contents. The authentic versions of the relevant acts, including their preambles, are those published in the Official\n",
      "Journal of the European Union and available in EUR-Lex. Those official texts are directly accessible through the links\n",
      "embedded in this document\n",
      "►B REGULATION (EU) 2017/745 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\n",
      "of 5 April 2017\n",
      "on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and\n",
      "Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC\n",
      "(Text with EEA relevance)\n",
      "(OJ L 117, 5.5.2017, p. 1)\n",
      "Amended by:\n",
      "Official Journal\n",
      "No page date\n",
      "►M1 Regulation (EU) 2020/561 of the European Parliament and of the L 130 18 24.4.2020\n",
      "Council of 23 April 2020\n",
      "►M2 Commission Delegated Regulation (EU) 2023/502 of 1 December 2022 L 70 1 8.3.2023' metadata={'source': 'document.pdf', 'file_path': 'document.pdf', 'page': 0, 'total_pages': 232, 'ModDate': \"D:20240808025522+02'00'\", 'Producer': '3-Heights(TM) PDF to PDF-A Converter Shell 4.7.24.2 (http://www.pdf-tools.com)', 'Title': 'CL2017R0745EN0040010.0001.3bi_cp 1..1', 'Author': 'Publications Office', 'Subject': ' ', 'Creator': 'Arbortext Advanced Print Publisher 10.0.1465/W Unicode', 'CreationDate': \"D:20240724041003-07'00'\", 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "# Using PDF document\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(\"document.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "pages = loader.load_and_split(text_splitter)\n",
    "\n",
    "print(pages[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and store the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store the embeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=pages, embedding=embeddings, persist_directory=\"db\")\n",
    "vectorstore = Chroma(persist_directory=\"db\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Retrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 16: which have been published in the Official Journal of the European\n",
      "Union, shall be presumed to be in conformity with the requirements\n",
      "of this Regulation covered by those standards or parts thereof.\n",
      "The first subparagraph shall also apply to system or process\n",
      "requirements to be fulfilled in accordance\n",
      "page 197: used, particularly as regards sterilisation and the relevant documents;\n",
      "and\n",
      "(e) the appropriate tests and trials which are to be carried out before,\n",
      "during and after manufacture, the frequency with which they are to\n",
      "take place, and the test equipment to be used; it shall be possible to\n",
      "trace back ad\n",
      "page 168: an initial start-up phase.\n",
      "1.6. Participation in coordination activities\n",
      "1.6.1. The notified body shall participate in, or ensure that its assessment\n",
      "personnel is informed of, any relevant standardisation activities and in\n",
      "the activities of the notified body coordination group referred to in\n",
      "Article\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"Describe the use of harmonised standards\")\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(\"page \" + str(doc.metadata[\"page\"] + 1) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ':\\n\\nThis is an extremely important question—how can a large proportion of people who may not speak the'},\n",
       " {'generated_text': ' to encourage good use of the same product\\n\\n(2)Where there is a strong preference among experts in'},\n",
       " {'generated_text': \", including the EU's 'Duke of Limbo' regulations as a 'guarantee that the countries\"},\n",
       " {'generated_text': ', one based on international practice of the EU.\\n\\n1. A national harmonised standard: whether under'},\n",
       " {'generated_text': '. I find that most of the information I have for a particular type of document has nothing to do with the'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2', max_length=1000, pad_token_id=50256, return_full_text=False)\n",
    "\n",
    "gpt2 = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "set_seed(42)\n",
    "generator(\"Describe the use of harmonised standards\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['content', 'additional_kwargs', 'response_metadata', 'type', 'name', 'id', 'example', 'tool_calls', 'invalid_tool_calls', 'usage_metadata'])\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "LLM stands for **Large Language Model**. It's a type of artificial intelligence (AI) that's specifically designed to understand and generate human-like text. \n",
       "\n",
       "Here's a breakdown of what makes LLMs special:\n",
       "\n",
       "* **Massive Datasets:** LLMs are trained on huge amounts of text data, like books, articles, code, and websites. This allows them to learn the nuances of language and how words are used in different contexts.\n",
       "* **Deep Learning:** LLMs use deep learning algorithms, which are complex mathematical models inspired by the human brain. These algorithms allow them to learn patterns and relationships within the data, enabling them to generate coherent and contextually relevant text.\n",
       "* **Natural Language Processing (NLP):** LLMs are a core component of NLP, which focuses on enabling computers to understand and interact with human language. They are used in various NLP tasks, such as text summarization, translation, question answering, and chatbot development.\n",
       "\n",
       "**Here are some examples of LLMs:**\n",
       "\n",
       "* **GPT-3 (Generative Pre-trained Transformer 3):** Developed by OpenAI, GPT-3 is one of the most powerful LLMs available. It can generate creative content, translate languages, write different kinds of creative content, and answer your questions in an informative way.\n",
       "* **LaMDA (Language Model for Dialogue Applications):** Developed by Google, LaMDA is designed specifically for conversational AI. It can engage in natural-sounding conversations, answering your questions and even holding opinions.\n",
       "* **BERT (Bidirectional Encoder Representations from Transformers):** Developed by Google, BERT is particularly good at understanding the context of words within a sentence. It's widely used in NLP tasks like sentiment analysis and question answering.\n",
       "\n",
       "**LLMs are rapidly evolving and have the potential to revolutionize many industries, including:**\n",
       "\n",
       "* **Content Creation:** Generating articles, stories, poems, and even code.\n",
       "* **Customer Service:** Providing automated support through chatbots.\n",
       "* **Education:** Personalizing learning experiences and providing interactive tutoring.\n",
       "* **Research:** Analyzing large datasets and generating reports.\n",
       "\n",
       "However, LLMs also raise ethical concerns, such as the potential for bias, misinformation, and job displacement. It's important to use LLMs responsibly and to be aware of their limitations.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "result = llm.invoke(\"What is an LLM?\")\n",
    "\n",
    "print(result.__dict__.keys())\n",
    "Markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "To be precise, a LLM should be a type that defines a set of parameters. The first argument to an implementation of an LLM is the form of the argument. The second argument is the argument's definition, the final form of the argument, and so on. These are called a \"argument semantics\". These semantics are also often referred to as the \"argument model\". It's the same concept as for types, and will hold even with some generalizations based on LLM's semantics. LLM's semantics are implemented in a number of different ways, and some examples are given in the following section.\n",
       "\n",
       "Basic LLMs\n",
       "\n",
       "First, make sure that the argument's definition has already been applied at initialization, otherwise LLM will call the type again without an argument in place. However, sometimes this can occur. For example, when an integer type is passed to a function, the type of the method returned is not guaranteed to come from a valid function. In this case you are forced to convert the name of the method to a valid function call. Alternatively, in some cases, you might omit the name of the method, so that the resulting type will resemble the class definition.\n",
       "\n",
       "Next, simply write the definition into the arguments, and then write the same for each argument as indicated in the LLM syntax.\n",
       "\n",
       "This is a few examples. The final form may be a list. Note, that every argument declaration has a certain format.\n",
       "\n",
       "If you include this version of a definition in your documentation, the compiler ignores all occurrences of the final version of the definition. This could cause you to break the grammar.\n",
       "\n",
       "If you specify you believe that this example is the first time a function is provided, this is the first time you'll ever use the \"f\" (for --) notation to evaluate a call in the definition.\n",
       "\n",
       "Other types may need to be specified and may also need to be called separately. This is where two values are taken off-line, and the \"name\" of the other is also taken off-line.\n",
       "\n",
       "The \"type\" of the rest of an input argument is usually taken from the form of a name of the type. In this example, the name of the type is not taken into account.\n",
       "\n",
       "The actual name of the variable, as defined, is given as a single list of \"types\".\n",
       "\n",
       "To call a method, you also need to specify a specific argument; typically what the method calls, the call context, and all the parameters you call it with. For example, the following might be interpreted as follows:\n",
       "\n",
       "return {... }\n",
       "\n",
       "This \"is\" option will call a method that gets a value returned.\n",
       "\n",
       "For more examples of how to write an LLM, see LLM vs. Type. In the next section, I'll present the problem with using the Type model and other classes (called \"class constructors\", or \"interface classes\") in class evaluation, in contrast to classes which are described below.\n",
       "\n",
       "The LLM model is essentially the idea behind all of this documentation. This particular article will take a look at the LLM model described below by the name of a variable, the class, and the name of the methods and arguments.\n",
       "\n",
       "LLLM Models\n",
       "\n",
       "LLLM also refers to other types. For example, here is the LLM syntax for a method on some object.\n",
       "\n",
       "type F = f a b... object F.prototype : (f: F) -> f... F.prototype : (f: F) -> f (object F)\n",
       "\n",
       "The name, type, and constructor parameters may be assigned when defining an instance(or the object instance if not a constructor or an instanceclass). This is useful for defining generic methods to be used in an application.\n",
       "\n",
       "This way: an instance function can be passed as an argument. If an instance variable is passed to f(foo), the given function will be called by doing something like this:\n",
       "\n",
       "let foo = new Foo // foo is a constructor. let f a = new Foo // foo is a supertype (class F);\n",
       "\n",
       "For example, you may want to take a copy argument to f(foo); and define the following:\n",
       "\n",
       "let f = new Foo // foo is a supertype (class F);\n",
       "\n",
       "The argument(s) function as indicated by the type is not only called by f(foo)(), but also by (f f a ) which is then called by doing nothing like this:\n",
       "\n",
       "let f = new Foo // foo is in a constructor. let f a = new Foo // foo is a supertype (class F);\n",
       "\n",
       "The constructor, f'. This method calls an object instance of F and prints out the following:\n",
       "\n",
       "let f = new Foo // foo is"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_gpt2 = gpt2.invoke(\"What is an LLM?\")\n",
    "Markdown(result_gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Use three sentences maximum and keep the answer as concise as possible. Mention in which pages the answer is found.\n",
      "\n",
      "filler context\n",
      "\n",
      "Question: filler question\n",
      "\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible. Mention in which pages the answer is found.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "example_messages\n",
    "\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Harmonized standards, published in the Official Journal of the European Union, are presumed to meet the requirements of the regulation. This applies to quality management systems, risk management, and other aspects of the manufacturing process. (Page 16) Notified bodies are required to assess conformity with harmonized standards related to quality management systems. (Page 197) \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        page_number = doc.metadata[\"page\"] + 1 \n",
    "        content_with_page = f\"Page {page_number}:\\n{doc.page_content}\"\n",
    "        formatted_docs.append(content_with_page)\n",
    "    return \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")\n",
    "\n",
    "query = \"Describe the use of harmonised standards\"\n",
    "Markdown(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Describe the use of harmonised standards',\n",
       " 'result': 'Harmonized standards, whose references have been published in the Official Journal of the European Union, are presumed to meet the requirements of the Regulation. This applies to both product requirements and system or process requirements. (Pages 1 and 2) \\n',\n",
       " 'source_documents': [Document(metadata={'Author': 'Publications Office', 'CreationDate': \"D:20240724041003-07'00'\", 'Creator': 'Arbortext Advanced Print Publisher 10.0.1465/W Unicode', 'ModDate': \"D:20240808025522+02'00'\", 'Producer': '3-Heights(TM) PDF to PDF-A Converter Shell 4.7.24.2 (http://www.pdf-tools.com)', 'Subject': ' ', 'Title': 'CL2017R0745EN0040010.0001.3bi_cp 1..1', 'file_path': 'document.pdf', 'page': 15, 'source': 'document.pdf', 'start_index': 1522, 'total_pages': 232}, page_content='which have been published in the Official Journal of the European\\nUnion, shall be presumed to be in conformity with the requirements\\nof this Regulation covered by those standards or parts thereof.\\nThe first subparagraph shall also apply to system or process\\nrequirements to be fulfilled in accordance with this Regulation by\\neconomic operators or sponsors, including those relating to quality\\nmanagement systems, risk management, post-market surveillance\\nsystems, clinical investigations, clinical evaluation or post-market\\nclinical follow-up (‘PMCF’).\\nReferences in this Regulation to harmonised standards shall be\\nunderstood as meaning harmonised standards the references of which\\nhave been published in the Official Journal of the European Union.'),\n",
       "  Document(metadata={'Author': 'Publications Office', 'CreationDate': \"D:20240724041003-07'00'\", 'Creator': 'Arbortext Advanced Print Publisher 10.0.1465/W Unicode', 'ModDate': \"D:20240808025522+02'00'\", 'Producer': '3-Heights(TM) PDF to PDF-A Converter Shell 4.7.24.2 (http://www.pdf-tools.com)', 'Subject': ' ', 'Title': 'CL2017R0745EN0040010.0001.3bi_cp 1..1', 'file_path': 'document.pdf', 'page': 196, 'source': 'document.pdf', 'start_index': 801, 'total_pages': 232}, page_content='used, particularly as regards sterilisation and the relevant documents;\\nand\\n(e) the appropriate tests and trials which are to be carried out before,\\nduring and after manufacture, the frequency with which they are to\\ntake place, and the test equipment to be used; it shall be possible to\\ntrace back adequately the calibration of that test equipment.\\nIn addition, the manufacturer shall grant the notified body access to the\\ntechnical documentation referred to in Annexes II and III.\\n2.3. Audit\\nThe notified body shall audit the quality management system to determine\\nwhether it meets the requirements referred to in Section 2.2. Where the\\nmanufacturer uses a harmonised standard or CS related to a quality\\nmanagement system, the notified body shall assess conformity with\\nthose standards or CS. The notified body shall assume that a quality\\nmanagement system which satisfies the relevant harmonised standards or\\nCS conforms to the requirements covered by those standards or CS, unless'),\n",
       "  Document(metadata={'Author': 'Publications Office', 'CreationDate': \"D:20240724041003-07'00'\", 'Creator': 'Arbortext Advanced Print Publisher 10.0.1465/W Unicode', 'ModDate': \"D:20240808025522+02'00'\", 'Producer': '3-Heights(TM) PDF to PDF-A Converter Shell 4.7.24.2 (http://www.pdf-tools.com)', 'Subject': ' ', 'Title': 'CL2017R0745EN0040010.0001.3bi_cp 1..1', 'file_path': 'document.pdf', 'page': 167, 'source': 'document.pdf', 'start_index': 818, 'total_pages': 232}, page_content='an initial start-up phase.\\n1.6. Participation in coordination activities\\n1.6.1. The notified body shall participate in, or ensure that its assessment\\npersonnel is informed of, any relevant standardisation activities and in\\nthe activities of the notified body coordination group referred to in\\nArticle 49 and that its assessment and decision-making personnel are\\ninformed of all relevant legislation, guidance and best practice\\ndocuments adopted in the framework of this Regulation.\\n1.6.2. The notified body shall take into consideration guidance and best practice\\ndocuments.\\n2. QUALITY MANAGEMENT REQUIREMENTS\\n2.1. The notified body shall establish, document, implement, maintain and\\noperate a quality management system that is appropriate to the nature,\\narea and scale of its conformity assessment activities and is capable of\\nsupporting and demonstrating the consistent fulfilment of the requirements\\nof this Regulation.')]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain.invoke({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but the provided text does not contain any information about \"LLM.\" \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(rag_chain.invoke(\"What is an LLM?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcacf19356d148f4bc6307722f0b07cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='Input:', layout=Layout(width='500px'), placeholder='Type …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682d31949e4746de977c403ed39c4bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1ee44c8c8a4cdf9be22f919c6a7290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('Complete generated prompt',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62a7de0a76d43ec91b714e7cd3bd1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Function that processes the user's question\n",
    "def process_input(user_input):\n",
    "    complete_prompt = f\"WIP\"\n",
    "    answer = rag_chain.invoke(user_input)\n",
    "    return answer, complete_prompt\n",
    "\n",
    "# Text input widget (for user question)\n",
    "text_input = widgets.Text(\n",
    "    description='Input:',\n",
    "    placeholder='Type something here...',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Primary output widget to display LLM's answer\n",
    "primary_output = widgets.Output()\n",
    "\n",
    "# Secondary output widget for the complete generated prompt (collapsible)\n",
    "secondary_output = widgets.Output()\n",
    "\n",
    "# Progress indicator (shown while processing)\n",
    "progress_indicator = widgets.Output()\n",
    "\n",
    "# Event handler for when Enter is pressed in the text input\n",
    "def on_text_submit(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        input_value = change.new.strip()\n",
    "        if input_value == \"\":\n",
    "            return\n",
    "\n",
    "        # Show the progress indicator\n",
    "        with progress_indicator:\n",
    "            progress_indicator.clear_output()\n",
    "            print(\"Processing... Please wait.\")\n",
    "\n",
    "        answer, complete_prompt = process_input(input_value)  # Processes the input\n",
    "\n",
    "        with primary_output:\n",
    "            primary_output.clear_output()       # Clears the previous output\n",
    "            print(f\"User Question: {input_value}\")\n",
    "            print(\"LLM Answer:\")\n",
    "            print(answer)\n",
    "\n",
    "        with secondary_output:\n",
    "            secondary_output.clear_output()     # Clears the previous output\n",
    "            print(\"Complete prompt:\")\n",
    "            print(complete_prompt)\n",
    "\n",
    "        # Hide the progress indicator after processing is complete\n",
    "        with progress_indicator:\n",
    "            progress_indicator.clear_output()\n",
    "\n",
    "        change.new = \"\"\n",
    "\n",
    "# Attach the event handler to the text input widget for Enter key submission\n",
    "text_input.continuous_update = False\n",
    "text_input.observe(on_text_submit, names='value', type=\"change\")\n",
    "\n",
    "# Make the complete generated prompt collapsible\n",
    "accordion = widgets.Accordion(children=[secondary_output])\n",
    "accordion.set_title(0, 'Complete generated prompt')\n",
    "\n",
    "# Display all the fields: text input, LLM's answer, complete prompt\n",
    "display(text_input, primary_output, accordion, progress_indicator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
